# Neural Machine Translation

Discover some of the shortcomings of a traditional seq2seq model and how to solve for them by adding an attention mechanism, then build a Neural Machine Translation model with Attention that translates English sentences into German.

## Learning Objectives

* Explain how an Encoder/Decoder model works
* Apply word alignment for machine translation
* Train a Neural Machine Translation model with Attention
* Develop intuition for how teacher forcing helps a translation model checks its predictions
* Use BLEU score and ROUGE score to evaluate machine-generated text quality
* Describe several decoding methods including MBR and Beam search
