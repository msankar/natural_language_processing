# Vector Space Models

Vector space models capture semantic meaning and relationships between words. You'll learn how to create word vectors that capture dependencies between words, then visualize their relationships in two dimensions using PCA.

## Learning Objectives
* Covariance matrices
* Dimensionality reduction
* Principal component analysis
* Cosine similarity
* Euclidean distance
* Co-occurrence matrices
* Vector representations
* Vector space models