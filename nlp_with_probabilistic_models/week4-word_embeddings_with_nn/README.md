# Word embeddings with neural networks

Learn about how word embeddings carry the semantic meaning of words, which makes them much more powerful for NLP tasks, then build your own Continuous bag-of-words model to create word embeddings from Shakespeare text.

## Learning Objectives
* Gradient descent
* One-hot vectors
* Neural networks
* Word embeddings
* Continuous bag-of-words model
* Text pre-processing
* Tokenization
* Data generators
