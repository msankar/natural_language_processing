# Recurrent Neural Networks for Language Modeling

Learn about the limitations of traditional language models and see how RNNs and GRUs use sequential data for text prediction. Then build your own next-word generator using a simple RNN on Shakespeare text data!

## Learning Objectives
* N-grams
* Gated recurrent units
* Recurrent neural networks
